name: Daily AI News Crawler

on:
  schedule:
    # Executar todos os dias às 08:00 UTC (05:00 BRT)
    - cron: '0 8 * * *'
    # Executar todos os dias às 18:00 UTC (15:00 BRT)
    - cron: '0 20 * * *'
  
  # Permitir execução manual
  workflow_dispatch:

jobs:
  crawl-and-analyze:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create environment file
      run: |
        echo "OPENROUTER_API_KEY=${{ secrets.OPENROUTER_API_KEY }}" >> .env
        echo "OPENROUTER_BASE_URL=https://openrouter.ai/api/v1" >> .env
        echo "DEFAULT_MODEL=anthropic/claude-3-haiku" >> .env
        echo "MAX_NEWS_PER_SOURCE=10" >> .env
        echo "OUTPUT_DIR=news_data" >> .env
        echo "HTML_OUTPUT_DIR=docs" >> .env
    
    - name: Run AI News Crawler
      run: |
        python run_once.py
    
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add docs/
        git add news_data/
        git add logs/
        
        # Verificar se há mudanças para commit
        if git diff --staged --quiet; then
          echo "Nenhuma mudança para commit"
        else
          git commit -m "🤖 Atualização automática de notícias - $(date '+%Y-%m-%d %H:%M:%S')"
          git push
        fi
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      if: github.ref == 'refs/heads/main'
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./docs
        publish_branch: gh-pages
        
    - name: Create deployment summary
      run: |
        echo "## 🤖 AI News Crawler - Execução Concluída" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Data/Hora:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "docs" ]; then
          echo "**Arquivos HTML gerados:** ✅" >> $GITHUB_STEP_SUMMARY
        else
          echo "**Arquivos HTML gerados:** ❌" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "news_data" ]; then
          NEWS_COUNT=$(find news_data -name "*.json" | wc -l)
          echo "**Arquivos de notícias:** $NEWS_COUNT" >> $GITHUB_STEP_SUMMARY
        else
          echo "**Arquivos de notícias:** 0" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Site disponível em:** https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}" >> $GITHUB_STEP_SUMMARY